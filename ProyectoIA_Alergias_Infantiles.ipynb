{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zapata-git/ProyectoIA_Alergias_Infantiles/blob/main/ProyectoIA_Alergias_Infantiles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ProyectoIA_Alergias_Infantiles**\n",
        "*Este conjunto de datos contiene información sobre reacciones alérgicas de niños a diferentes tipos de alimentos. Los datos se recopilaron de varios estudios y encuestas realizadas en diferentes países*\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ozL5OfH7B_kQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cEOP_ZC5Be7G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7951f9d4-8964-473d-c4a0-906c25bd5b5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el conjunto de datos\n",
        "\n",
        "datos = pd.read_csv(\"/content/drive/MyDrive/Proyecto_Alergias/food-allergy-analysis-Zenodo.csv\")\n",
        "datos.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peuSiVHSCdPN",
        "outputId": "85edf9ce-9b72-4824-aebf-d8a216192362"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(333200, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Limpieza de los datos \n",
        "\n",
        "datos.dtypes"
      ],
      "metadata": {
        "id": "5gSliNZd6Tsr",
        "outputId": "fb56b0f7-3c6f-4d51-bb09-12a33b2c8d7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SUBJECT_ID                   int64\n",
              "BIRTH_YEAR                   int64\n",
              "GENDER_FACTOR               object\n",
              "RACE_FACTOR                 object\n",
              "ETHNICITY_FACTOR            object\n",
              "PAYER_FACTOR                object\n",
              "ATOPIC_MARCH_COHORT           bool\n",
              "AGE_START_YEARS            float64\n",
              "AGE_END_YEARS              float64\n",
              "SHELLFISH_ALG_START        float64\n",
              "SHELLFISH_ALG_END          float64\n",
              "FISH_ALG_START             float64\n",
              "FISH_ALG_END               float64\n",
              "MILK_ALG_START             float64\n",
              "MILK_ALG_END               float64\n",
              "SOY_ALG_START              float64\n",
              "SOY_ALG_END                float64\n",
              "EGG_ALG_START              float64\n",
              "EGG_ALG_END                float64\n",
              "WHEAT_ALG_START            float64\n",
              "WHEAT_ALG_END              float64\n",
              "PEANUT_ALG_START           float64\n",
              "PEANUT_ALG_END             float64\n",
              "SESAME_ALG_START           float64\n",
              "SESAME_ALG_END             float64\n",
              "TREENUT_ALG_START          float64\n",
              "TREENUT_ALG_END            float64\n",
              "WALNUT_ALG_START           float64\n",
              "WALNUT_ALG_END             float64\n",
              "PECAN_ALG_START            float64\n",
              "PECAN_ALG_END              float64\n",
              "PISTACH_ALG_START          float64\n",
              "PISTACH_ALG_END            float64\n",
              "ALMOND_ALG_START           float64\n",
              "ALMOND_ALG_END             float64\n",
              "BRAZIL_ALG_START           float64\n",
              "BRAZIL_ALG_END             float64\n",
              "HAZELNUT_ALG_START         float64\n",
              "HAZELNUT_ALG_END           float64\n",
              "CASHEW_ALG_START           float64\n",
              "CASHEW_ALG_END             float64\n",
              "ATOPIC_DERM_START          float64\n",
              "ATOPIC_DERM_END            float64\n",
              "ALLERGIC_RHINITIS_START    float64\n",
              "ALLERGIC_RHINITIS_END      float64\n",
              "ASTHMA_START               float64\n",
              "ASTHMA_END                 float64\n",
              "FIRST_ASTHMARX             float64\n",
              "LAST_ASTHMARX              float64\n",
              "NUM_ASTHMARX               float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear DataFrame booleano indicando valores faltantes\n",
        "valores_faltantes = datos.isnull()\n",
        "\n",
        "# Obtener la cantidad total de valores faltantes por columna\n",
        "cantidad_faltantes = valores_faltantes.sum()\n",
        "cantidad_faltantes"
      ],
      "metadata": {
        "id": "129pr86H8YXE",
        "outputId": "3d5eb2ff-d467-4508-b6c8-c57cf998e1d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SUBJECT_ID                      0\n",
              "BIRTH_YEAR                      0\n",
              "GENDER_FACTOR                   0\n",
              "RACE_FACTOR                     0\n",
              "ETHNICITY_FACTOR                0\n",
              "PAYER_FACTOR                    0\n",
              "ATOPIC_MARCH_COHORT             0\n",
              "AGE_START_YEARS                 0\n",
              "AGE_END_YEARS                   0\n",
              "SHELLFISH_ALG_START        327954\n",
              "SHELLFISH_ALG_END          332149\n",
              "FISH_ALG_START             331404\n",
              "FISH_ALG_END               332673\n",
              "MILK_ALG_START             325911\n",
              "MILK_ALG_END               328620\n",
              "SOY_ALG_START              330781\n",
              "SOY_ALG_END                331769\n",
              "EGG_ALG_START              327135\n",
              "EGG_ALG_END                329907\n",
              "WHEAT_ALG_START            332054\n",
              "WHEAT_ALG_END              332512\n",
              "PEANUT_ALG_START           324547\n",
              "PEANUT_ALG_END             331108\n",
              "SESAME_ALG_START           332434\n",
              "SESAME_ALG_END             333022\n",
              "TREENUT_ALG_START          333199\n",
              "TREENUT_ALG_END            333200\n",
              "WALNUT_ALG_START           332496\n",
              "WALNUT_ALG_END             333034\n",
              "PECAN_ALG_START            332915\n",
              "PECAN_ALG_END              333141\n",
              "PISTACH_ALG_START          332831\n",
              "PISTACH_ALG_END            333118\n",
              "ALMOND_ALG_START           332814\n",
              "ALMOND_ALG_END             333083\n",
              "BRAZIL_ALG_START           333132\n",
              "BRAZIL_ALG_END             333181\n",
              "HAZELNUT_ALG_START         332947\n",
              "HAZELNUT_ALG_END           333148\n",
              "CASHEW_ALG_START           332639\n",
              "CASHEW_ALG_END             333079\n",
              "ATOPIC_DERM_START          283685\n",
              "ATOPIC_DERM_END            291468\n",
              "ALLERGIC_RHINITIS_START    277633\n",
              "ALLERGIC_RHINITIS_END      307874\n",
              "ASTHMA_START               269326\n",
              "ASTHMA_END                 307735\n",
              "FIRST_ASTHMARX             215650\n",
              "LAST_ASTHMARX              215650\n",
              "NUM_ASTHMARX               215650\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_value = datos['MILK_ALG_START'].mean()\n",
        "datos['MILK_ALG_START'].fillna(mean_value, inplace=True)\n"
      ],
      "metadata": {
        "id": "tixRM9CXEKK1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear DataFrame booleano indicando valores faltantes\n",
        "valores_faltantes = datos.isnull()\n",
        "\n",
        "# Obtener la cantidad total de valores faltantes por columna\n",
        "cantidad_faltantes = valores_faltantes.sum()\n",
        "cantidad_faltantes"
      ],
      "metadata": {
        "id": "xQZ8NNBlESEH",
        "outputId": "91b84fad-bfb5-468e-f545-85861a6eec8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SUBJECT_ID                      0\n",
              "BIRTH_YEAR                      0\n",
              "GENDER_FACTOR                   0\n",
              "RACE_FACTOR                     0\n",
              "ETHNICITY_FACTOR                0\n",
              "PAYER_FACTOR                    0\n",
              "ATOPIC_MARCH_COHORT             0\n",
              "AGE_START_YEARS                 0\n",
              "AGE_END_YEARS                   0\n",
              "SHELLFISH_ALG_START        327954\n",
              "SHELLFISH_ALG_END          332149\n",
              "FISH_ALG_START             331404\n",
              "FISH_ALG_END               332673\n",
              "MILK_ALG_START                  0\n",
              "MILK_ALG_END               328620\n",
              "SOY_ALG_START              330781\n",
              "SOY_ALG_END                331769\n",
              "EGG_ALG_START              327135\n",
              "EGG_ALG_END                329907\n",
              "WHEAT_ALG_START            332054\n",
              "WHEAT_ALG_END              332512\n",
              "PEANUT_ALG_START           324547\n",
              "PEANUT_ALG_END             331108\n",
              "SESAME_ALG_START           332434\n",
              "SESAME_ALG_END             333022\n",
              "TREENUT_ALG_START          333199\n",
              "TREENUT_ALG_END            333200\n",
              "WALNUT_ALG_START           332496\n",
              "WALNUT_ALG_END             333034\n",
              "PECAN_ALG_START            332915\n",
              "PECAN_ALG_END              333141\n",
              "PISTACH_ALG_START          332831\n",
              "PISTACH_ALG_END            333118\n",
              "ALMOND_ALG_START           332814\n",
              "ALMOND_ALG_END             333083\n",
              "BRAZIL_ALG_START           333132\n",
              "BRAZIL_ALG_END             333181\n",
              "HAZELNUT_ALG_START         332947\n",
              "HAZELNUT_ALG_END           333148\n",
              "CASHEW_ALG_START           332639\n",
              "CASHEW_ALG_END             333079\n",
              "ATOPIC_DERM_START          283685\n",
              "ATOPIC_DERM_END            291468\n",
              "ALLERGIC_RHINITIS_START    277633\n",
              "ALLERGIC_RHINITIS_END      307874\n",
              "ASTHMA_START               269326\n",
              "ASTHMA_END                 307735\n",
              "FIRST_ASTHMARX             215650\n",
              "LAST_ASTHMARX              215650\n",
              "NUM_ASTHMARX               215650\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Identificacion de variables categoricas\n",
        "columnas_categoricas = datos.select_dtypes(['object', 'category', 'bool' ]).columns\n",
        "print(columnas_categoricas)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_PxkrIuBH3M",
        "outputId": "f1079b28-9bab-4f87-a9cb-3f07f8917d0b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['GENDER_FACTOR', 'RACE_FACTOR', 'ETHNICITY_FACTOR', 'PAYER_FACTOR',\n",
            "       'ATOPIC_MARCH_COHORT'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una copia del conjunto de datos original\n",
        "datos_encoded = datos.copy()\n",
        "\n",
        "# Aplicar one-hot encoding a las columnas categóricas\n",
        "datos_encoded = pd.get_dummies(datos_encoded, columns=['GENDER_FACTOR', 'RACE_FACTOR', 'ETHNICITY_FACTOR', 'PAYER_FACTOR','ATOPIC_MARCH_COHORT'])\n",
        "\n",
        "# Crear una instancia del scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Normalizar los datos\n",
        "datos_normalizados = scaler.fit_transform(datos_encoded)\n",
        "\n",
        "# Crear un nuevo DataFrame con los datos normalizados\n",
        "datos_normalizados_df = pd.DataFrame(datos_normalizados, columns=datos_encoded.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POQJy1NbFV9x",
        "outputId": "4c94cfde-5720-4485-8dfe-99828e227a59"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_data.py:461: RuntimeWarning: All-NaN slice encountered\n",
            "  data_min = np.nanmin(X, axis=0)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_data.py:462: RuntimeWarning: All-NaN slice encountered\n",
            "  data_max = np.nanmax(X, axis=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columnas_faltantes = set(datos.columns).difference(set(datos_normalizados_df.columns))\n",
        "print(columnas_faltantes)\n"
      ],
      "metadata": {
        "id": "CxQHs1tHprKu",
        "outputId": "2dbc9935-08c8-40df-c0be-109bf329ecf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ATOPIC_MARCH_COHORT', 'GENDER_FACTOR', 'RACE_FACTOR', 'PAYER_FACTOR', 'ETHNICITY_FACTOR'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos_normalizados_df = pd.DataFrame(datos_normalizados, columns=datos_encoded.columns)\n"
      ],
      "metadata": {
        "id": "E14wAgAftUiJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Forma de datos:\", datos.shape)\n",
        "print(\"Forma de datos normalizados:\", datos_normalizados_df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkkTL4ACuEmT",
        "outputId": "2f0fd866-d25a-44c9-fa2d-26ad5d02567d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma de datos: (333200, 50)\n",
            "Forma de datos normalizados: (333200, 58)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Separación de datos en conjunto de entrenamiento y prueba**\n",
        "\n",
        "Función **train_test_split** de la librería **sklearn.model_selection** para separar el conjunto de datos normalizados en dos conjuntos: uno de entrenamiento y otro de prueba.\n",
        "\n",
        "La variable **X** se asigna con todas las columnas del conjunto de datos normalizados excepto la columna 'LABEL', que representa la variable objetivo. Esta variable se asigna a la variable **y**.\n",
        "\n",
        "La función **train_test_split** toma como argumentos X, y, test_size y random_state. test_size representa el tamaño del conjunto de datos de prueba y random_state establece una semilla aleatoria para garantizar que la división de entrenamiento y prueba sea reproducible.\n",
        "\n",
        "La función devuelve cuatro conjuntos de datos: \n",
        "* X_train, \n",
        "* X_test, \n",
        "* y_train, \n",
        "* y_test.\n",
        "\n",
        "\n",
        "**X_train** y **y_train** son los conjuntos de entrenamiento y **X_test** e **y_test** son los conjuntos de prueba."
      ],
      "metadata": {
        "id": "ipUw1imqkcXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'LABEL' in datos_normalizados_df.columns\n"
      ],
      "metadata": {
        "id": "IO0-4-RKwlJw",
        "outputId": "59a02b31-9493-4585-9dcb-25462a904612",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizar los datos\n",
        "scaler = MinMaxScaler()\n",
        "datos_normalizados = scaler.fit_transform(datos)\n",
        "\n",
        "# Convertir datos_normalizados a un DataFrame de pandas\n",
        "datos_normalizados_df = pd.DataFrame(datos_normalizados, columns=datos.columns)\n",
        "\n",
        "# Verificar que la columna 'LABEL' está presente en el DataFrame original\n",
        "if 'LABEL' in datos.columns:\n",
        "    # Agregar la columna 'LABEL' al DataFrame normalizado\n",
        "    datos_normalizados_df['LABEL'] = datos['LABEL']\n",
        "else:\n",
        "    print(\"La columna 'LABEL' no está presente en el DataFrame original\")\n",
        "\n",
        "# Dividir el conjunto de datos en entrenamiento y prueba\n",
        "X = datos_normalizados_df.drop(['LABEL'], axis=1) # todas las columnas menos 'LABEL'\n",
        "y = datos_normalizados_df['LABEL'] # la columna 'LABEL'\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "Y39knDwM0L_x",
        "outputId": "b795c2e1-a853-44f2-c0f6-1b11321a0aec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-a19ccd8e154e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Normalizar los datos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdatos_normalizados\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Convertir datos_normalizados a un DataFrame de pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mfirst_pass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    454\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_pass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m     def __array_wrap__(\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'S1 - Female'"
          ]
        }
      ]
    }
  ]
}